#! /usr/bin/env python
"""
Autotuning System

parameter_importance.py

A utility which attempts to rate the importance of the different parameters 
which were tuned. That is, which produced the greatest variation in score.

Usage:
./parameter_importance.py results.csv
"""

# Command line arguments
from optparse import OptionParser
# Reading in csv file
from common import readCSV, dict2key, score_range, avg_range





def main():
    
    # Command line arguments
    usage = "\n%prog results.csv\nWhere results.csv was generated by the auto-tuner."
    parser = OptionParser(usage=usage)
    
    options, args = parser.parse_args()
    
    if(len(args) != 1):
        parser.error("Expected a single CSV file argument.")
    csv_file = args[0]
    
    
    
    # Import the CSV data
    print "Reading '" + csv_file + "'"
    tests, vars, possValues, repeat = readCSV(csv_file)
    
    # tests is a list of tuples (test_no, valuation, score_list, score_overall)
    
    
    
    
    # Idea:
    # For each parameter, and each test, save the score to a list.
    # The lists are indexed by the valuation of all other parameters.
    # Remove all lists with only a single entry.
    # This gives, for each setting of outside parameters, the range of possible scores.
    
    importance = {}
    
    for var in vars:
        for t in tests:
            
            # Get the valuation of the OTHER parameters, in a canonical format.
            outsideValuation = dict(t[1]) #copies
            del outsideValuation[var]
            outsideValuation = dict2key(outsideValuation)
            
            # Get the score
            try:
                score = float(t[3])
            except ValueError:
                continue
            
            # Add the scores
            if importance.has_key(var):
                if importance[var].has_key(outsideValuation):
                    importance[var][outsideValuation].append(score)
                else:
                    importance[var][outsideValuation] = [score]
            else:
                importance[var] = {}
                importance[var][outsideValuation] = [score]
    
    # Remove singletons (these are when other parameters are varying)
    for var in importance.keys():
        for val in importance[var].keys():
            if len(importance[var][val]) <= 1:
                del importance[var][val]
    
    
    # Print data
    #for var, lists in importance.iteritems():
    #    for val, l in lists.iteritems():
    #        print "VAR: " + str(var)
    #        print "Valuation: " + str(val)
    #        print "Scores: " + str(l)
    #        print
    
    
    # Convert the lists of scores to ranges.
    for var in importance.keys():
        for val in importance[var].keys():
            importance[var][val] = score_range(importance[var][val])
    
    
    
    # Print data
    #print
    #for var, ranges in importance.iteritems():
    #    print "Parameter:     " + str(var)
    #    print "Score Ranges: " + str(ranges.values())
    #    print "Average Range: %.2f" % avg_range(ranges.values())
    #    print
    
    
    
    # Convert the lists of ranges into an average
    for var in importance.keys():
        importance[var] = avg_range(importance[var].values())
    
    
    
    # Print the importances sorted:
    print
    for var, imp in sorted(importance.items(), key=lambda x: x[1], reverse=True):
        print "Parameter: " + str(var)
        print "Variation: %#.3g" % imp # (average range)
        print
    
    
    
    
    











if __name__ == "__main__":
    main()
    
