#! /usr/bin/env python
"""
Autotuning System

output_screen.py

A utility to convert CSV tuning results files into graphs which are displayed 
on-screen.

Usage:
./output_screen.py results.csv

This process preserves the ordering of variables and possible values,
as given in the CSV file.
"""

# Command line arguments
from optparse import OptionParser
# Reading in csv file
from common import readCSV, score_std_dev, score_mean


# We need matplotlib for plotting, but it may not be available...
try:
    import matplotlib.pyplot as plt
except ImportError:
    print "The module 'matplotlib' is required for this script, which isn't available."
    exit()




def main():
    
    # Command Line Arguments
    # Read name of CSV file from command line
    
    usage = "\n%prog [options] results.csv\nWhere results.csv was generated by the auto-tuner."
    parser = OptionParser(usage=usage)
    
    parser.add_option("-r", "--reference", 
                        action="store", type="float", dest="reference",
                        help="Adds a 'reference' score line to the graph, showing how the tuner's results compare to a default score.",
                        metavar="SCORE")
    
    parser.add_option("-s", "--stddev", 
                        action="store_true", dest="std_dev", default=False,
                        help="Plot error bars showing the standard deviation of repeated tests from the mean.")
    
    options, args = parser.parse_args()
    
    if(len(args) != 1):
        parser.error("Expected a single CSV file argument.")
    csv_file = args[0]
    
    
    
    
    # Import the CSV data
    print "Reading '" + csv_file + "'"
    tests, vars, possValues, repeat = readCSV(csv_file)
    
    # tests is a list of tuples (test_no, valuation, score_list, score_overall)
    
    
    print "Displaying Graph"
    
    # Get a list of ALL test scores (incl overall scores).
    allResults = [r for t in tests for r in t[2] if r != ''] + [t[3] for t in tests if t[3] != '']
    if allResults == []:
        return False # There were no successful tests!
    
    allResults = map(float, allResults)
    if options.reference is not None:
        allResults.append(options.reference)
    
    maxResult = max(allResults)
    minResult = min(allResults)
    resultRange = maxResult - minResult
    
    
    
    # THE MAIN PLOT
    
    #plt.subplot(len(vars)+1, 1, 1)
    ax_main = plt.subplot(2, 1, 1) # Slight hack to get the main graph bigger
    
    
    
    # Get the data to plot
    overall_x = [t[0] for t in tests if t[3] != '']
    overall_y = [float(t[3]) for t in tests if t[3] != '']
    
    scores_xy = [([t[0] for t in tests if t[2][i] != ''], [t[2][i] for t in tests if t[2][i] != '']) for i in range(repeat)]
    
    if options.std_dev:
        overall_mean_x = [t[0]                for t in tests if t[3] != '' and len([x for x in t[2] if x !='']) > 1]
        overall_mean_y = [score_mean(t[2])    for t in tests if t[3] != '' and len([x for x in t[2] if x !='']) > 1]
        overall_err    = [score_std_dev(t[2]) for t in tests if t[3] != '' and len([x for x in t[2] if x !='']) > 1]
    
    
    
    plt.xlabel("")
    plt.ylabel("Score")
    
    
    
    
    plt.title("Tuning Results")
    
    # The main bar graph
    plt.bar(overall_x, overall_y, align='center', color='g')
    
    # Add error bars showing the std dev.
    if options.std_dev:
        ax_main.errorbar(overall_mean_x, overall_mean_y, yerr=overall_err, fmt=None)
    
    # Add the individual scores
    for (score_x, score_y) in scores_xy:
        plt.plot(score_x, score_y, 'rx')
    
    
    
    # If requested by the user, plot a "reference" measurement
    if options.reference is not None:
        plt.axhline(y=options.reference)
    
    
    
    # The area we show sould show all the points, but not necessarily extend down to 0.
    ymax = maxResult + resultRange*0.2
    ymin = max(minResult - resultRange*0.2, 0) if (minResult >= 0) else (minResult - resultRange*0.2)
    plt.axis([0, len(tests)+1, ymin, ymax])
    
    
    # Set xticks to auto, but do not include '0' or 'len(tests)+1' (the ends).
    # Should probably do this with a Locator, but wrote before i knew of them...
    xticks = plt.xticks()
    tick_list = xticks[0].tolist()
    tick_list.pop(0)
    tick_list.pop(-1)
    plt.xticks(tick_list, ""*len(tick_list)) # No Numbers
    
    
    ax_main.set_xticks(range(1, len(tests)+1), True) # Minor ticks
    
    ylabel_spacing = -0.1
    ax_main.yaxis.set_label_coords(ylabel_spacing, 0.5)
    
    
    # THE SUBPLOTS
    # Now do the subplots for the variable settings
    
    for i in range(len(vars)):
        
        #plt.subplot(len(vars)+1, 1, i+2)
        ax = plt.subplot(2*len(vars), 1, len(vars)+1+i, sharex=ax_main) # Position hack to get the main graph to appear bigger
        
        
        # get data to plot
        # Assuming there is data for all tests.
        var_x = [t[0] for t in tests]
        var_y = [possValues[vars[i]].index(t[1][vars[i]]) +1 for t in tests]
        
        plt.plot(var_x, var_y, 'ko')
        
        
        
        plt.ylabel(vars[i])
        
        plt.axis([0, len(tests)+1, 0, len(possValues[vars[i]])+1 ])
        
        plt.yticks(range(1, len(possValues[vars[i]])+1), possValues[vars[i]])
        
        
        # The last graph should have ticks along the bottom.
        if(i == len(vars)-1):
            plt.xticks(tick_list,) # Numbers
        else:
            plt.xticks(tick_list, ""*len(tick_list)) # No Numbers
        
        
        
        ax.yaxis.grid(True)
        ax.set_xticks(range(1, len(tests)+1), True)
        
        ax.yaxis.set_label_coords(ylabel_spacing, 0.5)
        
    
    
    # Bring them all touching
    plt.subplots_adjust(hspace=0.0)
    
    
    # Done!
    plt.show()
    
    
    
    
    
    print "Done"
    
    
    






if __name__ == "__main__":
    main()
    
