# Autotuning System
#
# template.conf
#
# A template configuration file.


# The configuration file must contain the following sections:
# [variables], [values], [testing], [scoring], [output] 


[variables]
# Contains a single option: 'variables'
# This lists the variables which will be tuned.
# This can either be a flat list: FOO, BAR, BAZ
# or a nested list, showing independence: {FOO, {BAR1, BAR2}, {BAZ1, BAZ2}}
# This syntax is explained fully in the User's Guide.

variables = 



[values]
# Lists the possible values each variable can take, e.g:
# FOO = 1, 2, 3
# BAR = Hello, Welcome, Hi


[testing]
# Shows how to compile and run the tests.
# Any of the following commands can use %FOO%, %BAR%, etc. as placeholders for 
# the variables named FOO and BAR which are being tuned.
# %%ID%% gives a unique test ID.


# compile (optional, default: none)
# Shell command to compile a test, typically a call to 'make' or similar.

compile = 


# test
# Shell command to run a test.

test = 


# clean (optional, default: none)
# Shell command to clean up (e.g. delete) any unwanted test files.

clean = 



[scoring]
# Options for how tests are scored to determine which is best.


# repeat (optional, default: 1, min)
# The number of times a test should be repeated.
# Also specifies how to aggregate the results of repeated tests into one 
# overall score for the test.
# Possible aggregates are: min, max, med, avg.
# If no aggregate is specified, 'min' is used as a default.
# e.g: "repeat = 3, avg" or "repeat = 4" ('min' implied)

repeat = 


# optimal (optional, default: min_time)
# Whether the highest or lowest score is considered best.
# Can be: min_time, max_time, min, max.
# If the '_time' versions are used, the system times the execution of the 
# 'test' command above and uses that as the score. Otherwise, the score is 
# taken from the last line of output from the 'test' command.

optimal = 




[output]
# SEts what types ouf output the tuner produces.

# log (optional)
# If defined, this is the name of a CSV file which a log of the tests 
# performed will be written to. If not defined, no log will be saved.
# This file will be overwritten!

log = 


# script (optional)
# If defined, a transcript of the tuning process will be written to this file.
# Only a summary of the tuning will be shown on screen.
# This file will be overwritten!

script = 


# importance (optional)
# If defined, this is a log file storing results from some extra tests which 
# will be run. These can be used with the parameter_importance utility to 
# determine which parameters have greatest effect.
# This file will be overwritten!

importance = 

